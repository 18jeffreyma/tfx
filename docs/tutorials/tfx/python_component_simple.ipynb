{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_component_simple.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "dMyhT3T-RGhl"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMyhT3T-RGhl",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright &copy; 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "831mkxc0RJCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRbWv0KF_oEl",
        "colab_type": "text"
      },
      "source": [
        "# Python Function Custom Component Example\n",
        "\n",
        "***An example of creating a custom component using the `@component` decorator***\n",
        "\n",
        "Note: We recommend running this tutorial in a Colab notebook, with no setup required!  Just click \"Run in Google Colab\".\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/python_component_simple\">\n",
        "<img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/python_component_simple.ipynb\">\n",
        "<img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/tfx/tree/master/docs/tutorials/tfx/python_component_simple.ipynb\">\n",
        "<img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a></td>\n",
        "</table></div>\n",
        "\n",
        "This tutorial shows how to create a new [custom component using a Python function and the `@component` decorator](https://www.tensorflow.org/tfx/guide/custom_function_component).\n",
        "\n",
        "This is intended as a \"Hello World\" example, showing:\n",
        "\n",
        "* Using the `@component` decorator and annotations to create a custom component\n",
        "* Loading and saving of artifacts\n",
        "* Parsing and update of a [Schema protocol buffer](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/schema.proto)\n",
        "* Adding a feature to the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQsm_p_bRt8U",
        "colab_type": "text"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "### Upgrade Pip\n",
        "\n",
        "To avoid upgrading Pip in a system when running locally, check to make sure that we're running in Colab.  Local systems can of course be upgraded separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "as4OTe2ukSqm",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### Install TFX\n",
        "\n",
        "**Note: In Google Colab, because of package updates, the first time you run this cell you must restart the runtime (Runtime > Restart runtime ...).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4SQA7Q5nej3",
        "colab": {}
      },
      "source": [
        "!pip install -q tfx==0.22.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "### Did you restart the runtime?\n",
        "\n",
        "If you are using Google Colab, the first time that you run the cell above, you must restart the runtime (Runtime > Restart runtime ...). This is because of the way that Colab loads packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N-ePgV0Lj68Q"
      },
      "source": [
        "### Import packages\n",
        "We import necessary packages, including standard TFX component classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YIqpWK9efviJ",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "tf.get_logger().propagate = False\n",
        "\n",
        "import tfx\n",
        "from tfx.components import CsvExampleGen\n",
        "from tfx.components import StatisticsGen\n",
        "from tfx.components import SchemaGen\n",
        "from tfx.components import ExampleValidator\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.types import Channel\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wCZTHRy0N1D6"
      },
      "source": [
        "Let's check the library versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eZ4K18_DN2D8",
        "colab": {}
      },
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ufJKQ6OvkJlY"
      },
      "source": [
        "### Set up pipeline paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ad5JLpKbf6sN",
        "colab": {}
      },
      "source": [
        "# This is the root directory for your TFX pip package installation.\n",
        "_tfx_root = tfx.__path__[0]\n",
        "\n",
        "# This is the directory containing the TFX Chicago Taxi Pipeline example.\n",
        "_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n",
        "\n",
        "# This is the path where your model will be pushed for serving.\n",
        "_serving_model_dir = os.path.join(\n",
        "    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n",
        "\n",
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n2cMMAbSkGfX"
      },
      "source": [
        "### Download example data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BywX6OUEhAqn",
        "colab": {}
      },
      "source": [
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
        "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "### Create the InteractiveContext\n",
        "Last, we create an InteractiveContext, which will allow us to run TFX components interactively in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Rh6K5sUf9dd",
        "colab": {}
      },
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## Run TFX components interactively\n",
        "In the cells that follow, we create and run TFX components one-by-one.  The first three components - `ExampleGen`, `StatisticsGen`, and `SchemaGen` - are initializing the metadata environment for `HelloComponent`.\n",
        "\n",
        "`HelloComponent` is the focus of this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvjQxlxCN1Vg",
        "colab_type": "text"
      },
      "source": [
        "### Ingest the Data With ExampleGen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PyXjuMt8f-9u",
        "colab": {}
      },
      "source": [
        "example_gen = CsvExampleGen(input=external_input(_data_root))\n",
        "context.run(example_gen, enable_cache=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrGcYEXlLA-R",
        "colab_type": "text"
      },
      "source": [
        "### Calculate the Dataset Statistics With StatisticsGen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFNGkXKGK7Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGlN3VikLTfC",
        "colab_type": "text"
      },
      "source": [
        "### Infer the Feature Types With SchemaGen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDfqWt6VLWTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "schema_gen = SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W-j6hYaXGop",
        "colab_type": "text"
      },
      "source": [
        "## Add the HelloComponent\n",
        "\n",
        "`HelloComponent` is our custom Python function component.  In it we read the dataset which was ingested by `ExampleGen` and the schema that was inferred by `SchemaGen`.  We then add a new feature to the dataset and schema, and output the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnbhpUZL_xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import six\n",
        "import tensorflow_data_validation as tfdv\n",
        "from tfx.dsl.component.experimental.annotations import OutputDict\n",
        "from tfx.dsl.component.experimental.annotations import InputArtifact\n",
        "from tfx.dsl.component.experimental.annotations import OutputArtifact\n",
        "from tfx.dsl.component.experimental.annotations import Parameter\n",
        "from tfx.dsl.component.experimental.decorators import component\n",
        "from tfx.types import artifact_utils\n",
        "from tfx.types.standard_artifacts import Examples\n",
        "from tfx.types.standard_artifacts import Schema\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "class _feature_utils(object):\n",
        "  @staticmethod\n",
        "  def _bytes_feature(value) -> tf.train.Feature:\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "      value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "    value = value[0] if value.size > 0 else bytes([]) \n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "  @staticmethod\n",
        "  def _float_feature(value) -> tf.train.Feature:\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    value = [] if value.numpy().size == 0 else [value]\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "  @staticmethod\n",
        "  def _int64_feature(value) -> tf.train.Feature:\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    value = [] if value.numpy().size == 0 else [value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "  @classmethod\n",
        "  def example_from_tensor_dict(cls, tensor_dict) -> tf.train.Example:\n",
        "    tfexample_dict = {}\n",
        "    for name, tensor in six.iteritems(tensor_dict):\n",
        "      val = tensor.values if hasattr(tensor, 'values') else tensor\n",
        "      if tensor.dtype == 'int64':\n",
        "        tfexample_dict[name] = cls._int64_feature(val)\n",
        "      elif tensor.dtype == 'float32':\n",
        "        tfexample_dict[name] = cls._float_feature(val)\n",
        "      elif tensor.dtype == 'string':\n",
        "        tfexample_dict[name] = cls._bytes_feature(val)\n",
        "      else:\n",
        "        raise ValueError('{} is an unknown type: {}'.format(name, tensor.dtype))\n",
        "    \n",
        "    return tf.train.Example(features=tf.train.Features(feature=tfexample_dict))\n",
        "\n",
        "@component\n",
        "def HelloComponent(\n",
        "    input_data: InputArtifact[Examples],\n",
        "    schema: InputArtifact[Schema],\n",
        "    output_data: OutputArtifact[Examples],\n",
        "    new_schema: OutputArtifact[Schema],\n",
        "    new_feature_name: Parameter[str],\n",
        "    component_name: Parameter[str]\n",
        "    ) -> None:\n",
        "  \n",
        "  schema_proto = tfdv.load_schema_text(os.path.join(schema.uri, 'schema.pbtxt'))\n",
        "  feature_spec, domains = schema_utils.schema_as_feature_spec(schema_proto)\n",
        "\n",
        "  # Get a list of the splits in input_data\n",
        "  splits_list = artifact_utils.decode_split_names(\n",
        "    split_names=input_data.split_names\n",
        "  )\n",
        "  \n",
        "  for split in splits_list:\n",
        "    input_dir = os.path.join(input_data.uri, split)\n",
        "    output_dir = os.path.join(output_data.uri, split)\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "    for tfrecord_filename in os.listdir(input_dir):\n",
        "      input_path = os.path.join(input_dir, tfrecord_filename)\n",
        "      output_path = os.path.join(output_dir, tfrecord_filename)\n",
        "      with tf.io.TFRecordWriter(output_path, options=\"GZIP\") as writer:\n",
        "        # Read each tfrecord file in the input split\n",
        "        for tfrecord in tf.data.TFRecordDataset(input_path, compression_type=\"GZIP\"):\n",
        "          tensor_dict = tf.io.parse_single_example(tfrecord, feature_spec)\n",
        "\n",
        "          # Imagine that we want to add a new feature\n",
        "          tensor_dict[new_feature_name] = tf.constant(42, dtype=tf.int64)\n",
        "          \n",
        "          result = _feature_utils.example_from_tensor_dict(tensor_dict)\n",
        "          writer.write(result.SerializeToString())\n",
        "\n",
        "  # Add the new feature to the schema\n",
        "  new_feature = schema_pb2.Feature(\n",
        "    name=new_feature_name,\n",
        "    type=schema_pb2.INT,\n",
        "    value_count={'min':1, 'max':1},\n",
        "    presence={'min_fraction': 1.0, 'min_count': 1}\n",
        "    )\n",
        "  schema_proto.feature.append(new_feature)\n",
        "  schema_path = os.path.join(new_schema.uri, 'schema.pbtxt')\n",
        "  tfdv.write_schema_text(schema_proto, schema_path)\n",
        "\n",
        "  # For completeness, encode the splits names.\n",
        "  # We could also just use input_data.split_names.\n",
        "  output_data.split_names = artifact_utils.encode_split_names(\n",
        "      splits=splits_list\n",
        "      )\n",
        "  \n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arMKRrcFc89H",
        "colab_type": "text"
      },
      "source": [
        "### Run HelloComponent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvn5puqZYUyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hello = HelloComponent(input_data=example_gen.outputs['examples'],\n",
        "                       schema=schema_gen.outputs['schema'],\n",
        "                       component_name=u'HelloWorld',\n",
        "                       new_feature_name=u'new_feature')\n",
        "context.run(hello, enable_cache=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V7DnpMROwJk",
        "colab_type": "text"
      },
      "source": [
        "### Examine the Output Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86ju-NWyZy-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_data = hello.outputs['output_data'].get()[0]\n",
        "print('output_data: splits={}, URI={}'.format(output_data.split_names, output_data.uri))\n",
        "\n",
        "new_schema = hello.outputs['new_schema'].get()[0]\n",
        "print('new_schema: URI={}'.format(new_schema.uri))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhM4wLnVaCGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(output_data.uri, 'train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 2 records and decode them.\n",
        "for tfrecord in dataset.take(2):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOCiF7qIP-dB",
        "colab_type": "text"
      },
      "source": [
        "### Examine the Updated Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZUVSjVjas_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context.show(hello.outputs['new_schema'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### Test With ExampleValidator\n",
        "\n",
        "Using ExampleValidator as a test, try using the output from HelloComponent.\n",
        "\n",
        "Note: Since we didn't update the statistics after adding a new feature, `ExampleValidator` should see this as an anomaly.  That's ok, because we've already run `ExampleValidator` on our original dataset to look for problems that we might not be aware of.  If you wanted to update the statistics, add another output artifact to `HelloComponent`, or follow `HelloComponent` with a second instance of `StatisticsGen`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MAscCCYWgA-9",
        "colab": {}
      },
      "source": [
        "example_validator = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=hello.outputs['new_schema'])\n",
        "context.run(example_validator, enable_cache=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0rcF88YLY5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}